{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e93f6889e5d24bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1️. Model Architecture Overview\n",
    "\n",
    "  **Multi-Scale 1-D CNN** zur Objekterkennung.\n",
    "\n",
    "  - **Input**: 1‑D Signal der Länge 163.\n",
    "  - **Parallel feature paths**: 2–4 convolutional Zweige mit verschiedenen Kernel-Größen und Anzahl an Filtern.\n",
    "  - **Global pooling**: Erzeugt eine Darstellung, die unabhängig vom Startpunkt des Scans ist.\n",
    "  - **Dense head**: Klassifiziert in verschiedene Objekte."
   ],
   "id": "80c65e6fee2139f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:31:28.610056800Z",
     "start_time": "2026-02-10T22:31:28.579893100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.signal import savgol_filter\n",
    "from training_pc.src.utils.data_processing import SmartAugmentor\n",
    "import numpy as np"
   ],
   "id": "62d69673a83a77ec",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Daten Preprocessing\n",
    "\n",
    "Bevor die Daten zum Trainieren des Models genutzt werden können, muss zuerst mit Ausreißern umgegangen werden. Zudem können die Daten noch gelättet werden, um weniger Rauschen zu bekommen.\n",
    "\n",
    " - **Ausreißer**: durch eine festgelegte maximale Distanz, können Messfehler durch den Sensor behoben werden. **Ausreißer --> Nan --> Interpolieren**; bereits bestehende NaN werden vorher rausgeworfen\n",
    "  - **Median-Filter**: entfernt noise\n",
    "  - **Savitzky-Golay-Filter**: \"glättet\" die Daten"
   ],
   "id": "fa1de3e66d83daaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, max_dist=15.0, steps=163):\n",
    "        self.max_dist = max_dist\n",
    "        self.steps = steps\n",
    "\n",
    "    def clean_scan(self, raw_distances):\n",
    "        denoised = median_filter(raw_distances, size=3)\n",
    "        smoothed = savgol_filter(denoised, window_length=11, polyorder=2)\n",
    "        return smoothed\n",
    "\n",
    "    def process_file(self, file_path, label_idx):\n",
    "        df = pd.read_csv(file_path, comment=\"#\").dropna(subset=[\"distance_cm\"])\n",
    "\n",
    "        df.loc[df[\"distance_cm\"] > self.max_dist, \"distance_cm\"] = np.nan\n",
    "\n",
    "        df[\"distance_cm\"] = df.groupby(\"scan_index\")[\"distance_cm\"].transform(\n",
    "            lambda x: x.interpolate().fillna(self.max_dist)\n",
    "        )\n",
    "\n",
    "        scans, labels = [], []\n",
    "\n",
    "        for s_id in df[\"scan_index\"].unique():\n",
    "            scan = df[df[\"scan_index\"] == s_id][\"distance_cm\"].values\n",
    "            cleaned = self.clean_scan(scan)\n",
    "            padded = np.pad(cleaned, (0, max(0, self.steps - len(cleaned))), mode='edge')[:self.steps]\n",
    "\n",
    "            scans.append(padded / self.max_dist)\n",
    "            labels.append(label_idx)\n",
    "\n",
    "        return np.array(scans), np.array(labels)"
   ],
   "id": "69e2dcc7df3148d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Augmentation\n",
    "\n",
    "  Durch das Augmentieren der Daten lernt das Model auch leicht veränderte Messungen durch zufällige Faktoren beim Messen zu erkennen. Außerdem wird das Model durch die leicht veränderten Daten robuster gegen Overfitting.\n",
    "\n",
    " - ``rotate_scan``: die Daten werden \"rotiert\", sodass, jeder Scan einen anderen Startpunkt hat\n",
    " - ``add_noise``: jedem Datenpunkt wird ein minimaler noise-Wert hinzugefügt (0 - 0.02)\n",
    " - ``jitter_scale``: simuliert verschiebung des Objektes auf dem Drehteller.\n"
   ],
   "id": "591f30ecdaef4cdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SmartAugmentor:\n",
    "    @staticmethod\n",
    "    def rotate_scan(scan, shift_range=20):\n",
    "        shift = np.random.randint(-shift_range, shift_range)\n",
    "        return np.roll(scan, shift, axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(scan, noise_level=0.02):\n",
    "        return scan + np.random.normal(0, noise_level, scan.shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def jitter_scale(scan, factor=0.05):\n",
    "        return scan * (1 + np.random.uniform(-factor, factor))"
   ],
   "id": "343402d615c45328",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Das Modell\n",
    "\n",
    "Wir verwenden ein Multi-Scale 1D-Convolutional Neural Network. Mit dem Multi-Scale Ansatz erreichen wir, dass das Modell einerseits kleine Feinheiten als auch die grobe Form erkennen kann. Das Convolutional Layer selbst ist da, um Formen zu erkennen."
   ],
   "id": "140dbcb4977d4535"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"Factory function for the Multi-Scale 1D-CNN architecture.\"\"\"\n",
    "    inputs = keras.Input(shape=(163, 1))\n",
    "    path_outputs = []\n",
    "\n",
    "    for i in range(hp.Int('num_paths', 2, 4)):\n",
    "        kernel_size = hp.Choice(f'kernel_{i}', [3, 7, 11, 15])\n",
    "        filters = hp.Int(f'filters_{i}', 16, 64, step=16)\n",
    "\n",
    "        x = layers.Conv1D(filters, kernel_size, padding='same', activation='relu')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        path_outputs.append(x)\n",
    "    merged = layers.Concatenate()(path_outputs)\n",
    "    x = layers.GlobalMaxPooling1D()(merged)\n",
    "\n",
    "    x = layers.Dense(hp.Int('dense_units', 32, 128, step=32), activation='relu')(x)\n",
    "    x = layers.Dropout(hp.Float('dropout', 0.1, 0.4, step=0.1))(x)\n",
    "\n",
    "    outputs = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    lr = hp.Float('lr', 1e-4, 1e-2, sampling='log')\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ],
   "id": "d27f41c7d1aa3d92"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
